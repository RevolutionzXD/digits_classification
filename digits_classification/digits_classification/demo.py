import torch
import matplotlib.pyplot as plt
from torchvision import datasets, transforms
from PIL import Image, ImageOps
import glob
import os
import random
import sys

# --- 1. Cáº¥u trÃºc Model (Copy y chang lÃºc train) ---
import torch.nn as nn
import torch.nn.functional as F

class SimpleMLP(nn.Module):
    def __init__(self, input_dim=784, hidden_dim=128, output_dim=10):
        super(SimpleMLP, self).__init__()
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        x = torch.flatten(x, 1)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# --- 2. CÃ¡c hÃ m xá»­ lÃ½ ---

def load_model(device):
    model = SimpleMLP(input_dim=784, hidden_dim=128, output_dim=10).to(device)
    path = "assets/model_final.pth"
    if not os.path.exists(path):
        print(f"âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y file '{path}'")
        sys.exit(1)
    
    try:
        checkpoint = torch.load(path, map_location=device, weights_only=True)
        model.load_state_dict(checkpoint)
        model.eval()
        print("âœ… ÄÃ£ load Model thÃ nh cÃ´ng!")
        return model
    except Exception as e:
        print(f"âŒ Lá»—i file model: {e}")
        sys.exit(1)

def mode_1_custom_images(model, device):
    print("\n--- CHáº¾ Äá»˜ 1: TEST áº¢NH Tá»° Váº¼ (FOLDER 'inputs') ---")
    image_paths = glob.glob("inputs/*.*")
    valid_exts = {'.jpg', '.jpeg', '.png', '.bmp'}
    image_paths = [f for f in image_paths if os.path.splitext(f)[1].lower() in valid_exts]

    if not image_paths:
        print("âš ï¸ KhÃ´ng tÃ¬m tháº¥y áº£nh nÃ o trong thÆ° má»¥c 'inputs'!")
        return

    transform = transforms.Compose([
        transforms.Resize((28, 28)),
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))
    ])

    print(f"ğŸ” TÃ¬m tháº¥y {len(image_paths)} áº£nh. (Táº¯t cá»­a sá»• Ä‘á»ƒ xem áº£nh káº¿ tiáº¿p)")
    
    for img_path in image_paths:
        try:
            # Xá»­ lÃ½ áº£nh
            orig_img = Image.open(img_path).convert('L')
            if orig_img.getpixel((0, 0)) > 128: # Náº¿u ná»n tráº¯ng -> Äáº£o mÃ u
                input_img = ImageOps.invert(orig_img)
                note = "ÄÃ£ Ä‘áº£o mÃ u ná»n"
            else:
                input_img = orig_img
                note = "Giá»¯ nguyÃªn mÃ u"

            # Dá»± Ä‘oÃ¡n
            img_tensor = transform(input_img).unsqueeze(0).to(device)
            with torch.no_grad():
                output = model(img_tensor)
                probs = torch.nn.functional.softmax(output, dim=1)
                pred = torch.argmax(probs, dim=1).item()
                conf = probs[0][pred].item() * 100

            # Hiá»ƒn thá»‹
            print(f"ğŸ“¸ áº¢nh: {os.path.basename(img_path)} -> AI Ä‘oÃ¡n: {pred} ({conf:.1f}%)")
            
            plt.figure(figsize=(4, 5))
            plt.imshow(input_img, cmap='gray')
            plt.title(f"AI Ä‘oÃ¡n: {pred}\n({conf:.1f}%)\n[{note}]", color='blue', fontsize=14)
            plt.axis('off')
            plt.show()

        except Exception as e:
            print(f"Lá»—i áº£nh {img_path}: {e}")

def mode_2_mnist_random(model, device):
    print("\n--- CHáº¾ Äá»˜ 2: TEST NGáºªU NHIÃŠN Tá»ª MNIST ---")
    print("â³ Äang táº£i dá»¯ liá»‡u Test...")
    
    # Transform hiá»ƒn thá»‹ (chá»‰ ToTensor)
    tf_display = transforms.ToTensor()
    # Transform dá»± Ä‘oÃ¡n (thÃªm Normalize)
    tf_predict = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))
    ])

    dataset_display = datasets.MNIST(root='data', train=False, download=True, transform=tf_display)
    dataset_predict = datasets.MNIST(root='data', train=False, download=True, transform=tf_predict)
    
    print("ğŸ‘‰ Táº¯t cá»­a sá»• áº£nh Ä‘á»ƒ xem táº¥m tiáº¿p theo. Báº¥m Ctrl+C trong terminal Ä‘á»ƒ quay láº¡i menu.")

    while True:
        try:
            idx = random.randint(0, len(dataset_display) - 1)
            img_show, label = dataset_display[idx]
            img_in, _ = dataset_predict[idx]

            # Dá»± Ä‘oÃ¡n
            img_in = img_in.unsqueeze(0).to(device)
            with torch.no_grad():
                output = model(img_in)
                probs = torch.nn.functional.softmax(output, dim=1)
                pred = torch.argmax(probs, dim=1).item()
                conf = probs[0][pred].item() * 100

            status = "ÄÃšNG âœ…" if pred == label else "SAI âŒ"
            color = 'green' if pred == label else 'red'

            print(f"Index [{idx}]: AI Ä‘oÃ¡n {pred} ({conf:.1f}%) | ÄÃ¡p Ã¡n: {label} -> {status}")

            plt.figure(figsize=(4, 5))
            plt.imshow(img_show.squeeze(), cmap='gray')
            plt.title(f"AI Ä‘oÃ¡n: {pred} ({conf:.1f}%)\nÄÃ¡p Ã¡n: {label}", color=color, fontsize=14, fontweight='bold')
            plt.axis('off')
            plt.show()
            
        except KeyboardInterrupt:
            break

# --- 3. ChÆ°Æ¡ng trÃ¬nh chÃ­nh ---

def main():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸš€ Khá»Ÿi Ä‘á»™ng Demo trÃªn: {device}")
    
    model = load_model(device)

    while True:
        print("\n" + "="*30)
        print("   MENU DEMO NHáº¬N DIá»†N Sá»")
        print("="*30)
        print("1. Test áº£nh tá»± váº½ (trong folder 'inputs')")
        print("2. Test ngáº«u nhiÃªn tá»« táº­p MNIST")
        print("0. ThoÃ¡t")
        
        choice = input("ğŸ‘‰ Chá»n cháº¿ Ä‘á»™ (0-2): ")

        if choice == '1':
            mode_1_custom_images(model, device)
        elif choice == '2':
            mode_2_mnist_random(model, device)
        elif choice == '0':
            print("ğŸ‘‹ Táº¡m biá»‡t!")
            break
        else:
            print("âŒ Chá»n sai rá»“i, nháº­p láº¡i Ä‘i Ã´ng!")

if __name__ == "__main__":
    main()