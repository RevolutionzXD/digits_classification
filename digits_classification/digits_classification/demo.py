import torch
import torch.nn as nn
import torch.nn.functional as F
import matplotlib.pyplot as plt
from torchvision import datasets, transforms
from PIL import Image, ImageOps
import glob
import os
import random
import sys

# --- 1. IMPORT C√ÅC MODEL (C·ªë g·∫Øng th·ª≠ m·ªçi c√°i t√™n c√≥ th·ªÉ) ---

# Th·ª≠ import MLP
try:
    from src.models.model import SimpleMLP
except ImportError:
    print("‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y class SimpleMLP")
    sys.exit(1)

# Th·ª≠ import CNN (Th·ª≠ t√™n 'CNN' tr∆∞·ªõc, n·∫øu kh√¥ng c√≥ th√¨ th·ª≠ 'SimpleCNN')
TargetCNNClass = None
HAS_CNN = False

try:
    from src.models.model import CNN
    TargetCNNClass = CNN
    HAS_CNN = True
    print("‚úÖ ƒê√£ t√¨m th·∫•y class: CNN")
except ImportError:
    try:
        from src.models.model import SimpleCNN
        TargetCNNClass = SimpleCNN
        HAS_CNN = True
        print("‚úÖ ƒê√£ t√¨m th·∫•y class: SimpleCNN")
    except ImportError:
        print("‚ö†Ô∏è C·∫£nh b√°o: Kh√¥ng t√¨m th·∫•y class CNN hay SimpleCNN. Ch·ªâ ch·∫°y ƒë∆∞·ª£c MLP.")
        HAS_CNN = False


# --- 2. H√ÄM LOAD MODEL ---
def load_model(device, model_type):
    model = None
    path = ""
    
    if model_type == 'mlp':
        print("\nüîÑ ƒêang kh·ªüi t·∫°o SimpleMLP...")
        model = SimpleMLP(input_dim=784, hidden_dim=128, output_dim=10).to(device)
        path = "assets/model_final.pth" 
        
    elif model_type == 'cnn':
        if not HAS_CNN or TargetCNNClass is None:
            print("‚ùå Code model.py ch∆∞a c√≥ class CNN!")
            return None
            
        print(f"\nüîÑ ƒêang kh·ªüi t·∫°o {TargetCNNClass.__name__}...")
        
        # Th·ª≠ kh·ªüi t·∫°o (c√≥ tham s·ªë ho·∫∑c kh√¥ng tham s·ªë)
        try:
            model = TargetCNNClass(num_classes=10).to(device)
        except TypeError:
            model = TargetCNNClass().to(device)
            
        # ‚ö†Ô∏è QUAN TR·ªåNG: Ki·ªÉm tra t√™n file CNN trong folder assets
        # N·∫øu √¥ng l∆∞u t√™n kh√°c (vd: best_model.pth) th√¨ nh·ªõ s·ª≠a d√≤ng d∆∞·ªõi n√†y!
        path = "assets/model_cnn_final.pth"
    
    # Ki·ªÉm tra file t·ªìn t·∫°i
    if not os.path.exists(path):
        print(f"\n‚ùå L·ªñI: Kh√¥ng t√¨m th·∫•y file tr·ªçng s·ªë '{path}'")
        print(f"üëâ B·∫°n ch·ªçn model {model_type.upper()} nh∆∞ng file .pth kh√¥ng c√≥ ·ªü ƒë√≥.")
        print("üëâ Ki·ªÉm tra l·∫°i xem th·∫±ng b·∫°n √¥ng l∆∞u file t√™n g√¨?")
        return None

    try:
        checkpoint = torch.load(path, map_location=device, weights_only=True)
        model.load_state_dict(checkpoint)
        model.eval()
        print(f"‚úÖ ƒê√£ load th√†nh c√¥ng: {path}")
        return model
    except Exception as e:
        print(f"‚ùå L·ªói khi load file tr·ªçng s·ªë: {e}")
        return None

# --- 3. CH·∫æ ƒê·ªò 1: TEST ·∫¢NH T·ª∞ V·∫º ---
def test_custom_images(model, device):
    print("\n--- üé® CH·∫æ ƒê·ªò TEST ·∫¢NH T·ª∞ V·∫º (Folder 'inputs') ---")
    image_paths = glob.glob("inputs/*.*")
    valid_exts = {'.jpg', '.jpeg', '.png', '.bmp'}
    image_paths = [f for f in image_paths if os.path.splitext(f)[1].lower() in valid_exts]

    if not image_paths:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y ·∫£nh trong folder 'inputs'!")
        return

    # Transform chu·∫©n
    transform = transforms.Compose([
        transforms.Resize((28, 28)),
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))
    ])

    print(f"üîé T√¨m th·∫•y {len(image_paths)} ·∫£nh. (T·∫Øt c·ª≠a s·ªï ƒë·ªÉ xem ti·∫øp)")

    for img_path in image_paths:
        try:
            orig_img = Image.open(img_path).convert('L')
            
            # ƒê·∫£o m√†u n·∫øu n·ªÅn tr·∫Øng
            if orig_img.getpixel((0, 0)) > 128: 
                input_img = ImageOps.invert(orig_img)
                note = "ƒê√£ ƒë·∫£o m√†u"
            else:
                input_img = orig_img
                note = "Gi·ªØ nguy√™n"

            img_tensor = transform(input_img).unsqueeze(0).to(device)
            
            with torch.no_grad():
                output = model(img_tensor)
                probs = F.softmax(output, dim=1)
                pred = probs.argmax(dim=1).item()
                conf = probs[0][pred].item() * 100

            print(f"üì∏ {os.path.basename(img_path)} -> AI ƒëo√°n: {pred} ({conf:.1f}%)")
            
            plt.figure(figsize=(5, 6))
            plt.imshow(input_img, cmap='gray')
            plt.title(f"Model: {model.__class__.__name__}\nAI ƒëo√°n: {pred} ({conf:.1f}%)\n[{note}]", color='blue')
            plt.axis('off')
            plt.show()

        except Exception as e:
            print(f"L·ªói ·∫£nh {img_path}: {e}")

# --- 4. CH·∫æ ƒê·ªò 2: TEST MNIST ---
def test_mnist(model, device):
    print("\n--- üé≤ TEST NG·∫™U NHI√äN T·ª™ MNIST ---")
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))
    ])
    dataset = datasets.MNIST('data', train=False, download=True, transform=transform)
    
    print("üëâ T·∫Øt ·∫£nh ƒë·ªÉ xem t·∫•m ti·∫øp theo. Ctrl+C ƒë·ªÉ tho√°t.\n")

    while True:
        try:
            idx = random.randint(0, len(dataset) - 1)
            img_tensor, label = dataset[idx]
            input_tensor = img_tensor.unsqueeze(0).to(device)
            
            with torch.no_grad():
                output = model(input_tensor)
                probs = F.softmax(output, dim=1)
                pred = probs.argmax(dim=1).item()
                conf = probs[0][pred].item() * 100
            
            status = "ƒê√öNG ‚úÖ" if pred == label else "SAI ‚ùå"
            color = 'green' if pred == label else 'red'
            
            print(f"Index [{idx}]: ƒêo√°n {pred} ({conf:.1f}%) | Th·∫≠t {label} -> {status}")
            
            plt.figure(figsize=(4, 5))
            plt.imshow(img_tensor.squeeze(), cmap='gray')
            plt.title(f"Model: {model.__class__.__name__}\nƒêo√°n: {pred} ({conf:.1f}%)\nƒê√°p √°n: {label}", color=color)
            plt.axis('off')
            plt.show()

        except KeyboardInterrupt:
            break

# --- 5. MENU CH√çNH ---
def main():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"üöÄ Device: {device}")

    while True:
        print("\n" + "="*40)
        print("   ü§ñ MENU DEMO - v2.0")
        print("="*40)
        print("1. Ch·∫°y MLP (C≈©)")
        print("2. Ch·∫°y CNN (M·ªõi)")
        print("0. Tho√°t")
        
        choice = input("üëâ Ch·ªçn (0-2): ")
        
        if choice == '0': break
            
        model = None
        if choice == '1': model = load_model(device, 'mlp')
        elif choice == '2': model = load_model(device, 'cnn')
        else: continue
            
        if model is None: continue

        while True:
            print(f"\n--- üß† Model: {model.__class__.__name__} ---")
            print("1. Test ·∫£nh t·ª± v·∫Ω")
            print("2. Test MNIST")
            print("3. Quay l·∫°i")
            
            c = input("üëâ Ch·ªçn: ")
            if c == '1': test_custom_images(model, device)
            elif c == '2': test_mnist(model, device)
            elif c == '3': break

if __name__ == "__main__":
    main()